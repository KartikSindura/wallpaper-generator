{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will get the dependencies and the Kohya_SS library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-31T07:01:40.383506Z",
     "iopub.status.busy": "2025-03-31T07:01:40.383165Z",
     "iopub.status.idle": "2025-03-31T07:08:09.813857Z",
     "shell.execute_reply": "2025-03-31T07:08:09.812679Z",
     "shell.execute_reply.started": "2025-03-31T07:01:40.383477Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/kohya_ss'...\n",
      "remote: Enumerating objects: 14874, done.\u001b[K\n",
      "remote: Counting objects: 100% (506/506), done.\u001b[K\n",
      "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
      "remote: Total 14874 (delta 455), reused 393 (delta 390), pack-reused 14368 (from 4)\u001b[K\n",
      "Receiving objects: 100% (14874/14874), 23.26 MiB | 31.33 MiB/s, done.\n",
      "Resolving deltas: 100% (10443/10443), done.\n",
      "/kaggle/working/kohya_ss\n",
      "Note: switching to '2853f4cec850557e83882a4072cfe416cb9c57d7'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at 2853f4c Merge pull request #1429 from bmaltais/dev2\n",
      "Skipping git operations.\n",
      "Ubuntu detected.\n",
      "Python TK found...\n",
      "Switching to virtual Python environment.\n",
      "\u001b[2;36m07:01:45-763422\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing python dependencies. This could take a few  \n",
      "\u001b[2;36m                \u001b[0m         minutes as it downloads files.                         \n",
      "\u001b[2;36m07:01:45-767372\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m If this operation ever runs too long, you can rerun    \n",
      "\u001b[2;36m                \u001b[0m         this script in verbose mode to check.                  \n",
      "\u001b[2;36m07:01:45-768506\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Version: v21.\u001b[1;36m8.8\u001b[0m                                       \n",
      "\u001b[2;36m                \u001b[0m                                                                \n",
      "\u001b[2;36m07:01:45-769492\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Python \u001b[1;36m3.10\u001b[0m.\u001b[1;36m12\u001b[0m on Linux                                \n",
      "\u001b[2;36m07:01:45-771542\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing modules from requirements_linux.txt\u001b[33m...\u001b[0m      \n",
      "\u001b[2;36m07:01:45-772697\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: torch \u001b[1;36m2.0\u001b[0m.\u001b[1;36m0\u001b[0m required \u001b[1;36m2.0\u001b[0m.\u001b[1;36m1\u001b[0m+cu118\n",
      "\u001b[2;36m07:01:45-773668\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mtorch\u001b[0m==\u001b[1;36m2.0\u001b[0m.\u001b[1;36m1\u001b[0m+cu118                 \n",
      "\u001b[2;36m                \u001b[0m         \u001b[33mtorchvision\u001b[0m==\u001b[1;36m0.15\u001b[0m.\u001b[1;36m2\u001b[0m+cu118 --extra-index-url            \n",
      "\u001b[2;36m                \u001b[0m         \u001b[4;94mhttps://download.pytorch.org/whl/cu118\u001b[0m                 \n",
      "\u001b[2;36m07:03:38-902349\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mxformers\u001b[0m==\u001b[1;36m0.0\u001b[0m.\u001b[1;36m20\u001b[0m                   \n",
      "\u001b[2;36m                \u001b[0m         \u001b[33mbitsandbytes\u001b[0m==\u001b[1;36m0.41\u001b[0m.\u001b[1;36m1\u001b[0m                                   \n",
      "\u001b[2;36m07:03:53-709257\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing modules from requirements.txt\u001b[33m...\u001b[0m            \n",
      "\u001b[2;36m07:03:53-710702\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: accelerate \u001b[1;36m0.22\u001b[0m.\u001b[1;36m0\u001b[0m required      \n",
      "\u001b[2;36m                \u001b[0m         \u001b[1;36m0.19\u001b[0m.\u001b[1;36m0\u001b[0m                                                 \n",
      "\u001b[2;36m07:03:53-711873\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33maccelerate\u001b[0m==\u001b[1;36m0.19\u001b[0m.\u001b[1;36m0\u001b[0m                 \n",
      "\u001b[2;36m07:04:02-700766\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: aiofiles \u001b[1;36m22.1\u001b[0m.\u001b[1;36m0\u001b[0m required \u001b[1;36m23.2\u001b[0m.\u001b[1;36m1\u001b[0m \n",
      "\u001b[2;36m07:04:02-702041\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33maiofiles\u001b[0m==\u001b[1;36m23.2\u001b[0m.\u001b[1;36m1\u001b[0m                   \n",
      "\u001b[2;36m07:04:10-102984\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: altair \u001b[1;36m5.1\u001b[0m.\u001b[1;36m0\u001b[0m required \u001b[1;36m4.2\u001b[0m.\u001b[1;36m2\u001b[0m     \n",
      "\u001b[2;36m07:04:10-104222\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33maltair\u001b[0m==\u001b[1;36m4.2\u001b[0m.\u001b[1;36m2\u001b[0m                      \n",
      "\u001b[2;36m07:04:18-154552\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mdadaptation\u001b[0m==\u001b[1;36m3.1\u001b[0m                   \n",
      "\u001b[2;36m07:04:36-491241\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: diffusers\u001b[1m[\u001b[0mtorch\u001b[1m]\u001b[0m==\u001b[1;36m0.18\u001b[0m.\u001b[1;36m2\u001b[0m           \n",
      "\u001b[2;36m07:04:44-723810\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33measygui\u001b[0m==\u001b[1;36m0.98\u001b[0m.\u001b[1;36m3\u001b[0m                    \n",
      "\u001b[2;36m07:04:52-308169\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33meinops\u001b[0m==\u001b[1;36m0.6\u001b[0m.\u001b[1;36m0\u001b[0m                      \n",
      "\u001b[2;36m07:04:59-675676\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mfairscale\u001b[0m==\u001b[1;36m0.4\u001b[0m.\u001b[1;36m13\u001b[0m                  \n",
      "\u001b[2;36m07:05:24-150885\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mftfy\u001b[0m==\u001b[1;36m6.1\u001b[0m.\u001b[1;36m1\u001b[0m                        \n",
      "\u001b[2;36m07:05:31-522910\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mgradio\u001b[0m==\u001b[1;36m3.36\u001b[0m.\u001b[1;36m1\u001b[0m                     \n",
      "\u001b[2;36m07:05:42-038801\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: huggingface-hub \u001b[1;36m0.16\u001b[0m.\u001b[1;36m4\u001b[0m required \n",
      "\u001b[2;36m                \u001b[0m         \u001b[1;36m0.15\u001b[0m.\u001b[1;36m1\u001b[0m                                                 \n",
      "\u001b[2;36m07:05:42-040079\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: huggingface-\u001b[33mhub\u001b[0m==\u001b[1;36m0.15\u001b[0m.\u001b[1;36m1\u001b[0m            \n",
      "\u001b[2;36m07:05:49-779977\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: invisible-\u001b[33mwatermark\u001b[0m==\u001b[1;36m0.2\u001b[0m.\u001b[1;36m0\u001b[0m         \n",
      "\u001b[2;36m07:05:57-361924\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: lion-\u001b[33mpytorch\u001b[0m==\u001b[1;36m0.0\u001b[0m.\u001b[1;36m6\u001b[0m                \n",
      "\u001b[2;36m07:06:04-979758\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mlycoris_lora\u001b[0m==\u001b[1;36m1.8\u001b[0m.\u001b[1;36m3\u001b[0m                \n",
      "\u001b[2;36m07:06:14-355422\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: open-clip-\u001b[33mtorch\u001b[0m==\u001b[1;36m2.20\u001b[0m.\u001b[1;36m0\u001b[0m            \n",
      "\u001b[2;36m07:06:22-129919\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: opencv-python \u001b[1;92m4.8.0.76\u001b[0m required \n",
      "\u001b[2;36m                \u001b[0m         \u001b[1;92m4.7.0.68\u001b[0m                                               \n",
      "\u001b[2;36m07:06:22-131213\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: opencv-\u001b[33mpython\u001b[0m==\u001b[1;92m4.7.0.68\u001b[0m            \n",
      "\u001b[2;36m07:06:33-219960\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mprodigyopt\u001b[0m==\u001b[1;36m1.0\u001b[0m                    \n",
      "\u001b[2;36m07:06:40-814728\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: pytorch-lightning \u001b[1;36m2.0\u001b[0m.\u001b[1;36m7\u001b[0m required\n",
      "\u001b[2;36m                \u001b[0m         \u001b[1;36m1.9\u001b[0m.\u001b[1;36m0\u001b[0m                                                  \n",
      "\u001b[2;36m07:06:40-816059\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: pytorch-\u001b[33mlightning\u001b[0m==\u001b[1;36m1.9\u001b[0m.\u001b[1;36m0\u001b[0m           \n",
      "\u001b[2;36m07:06:49-217987\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: rich \u001b[1;36m13.4\u001b[0m.\u001b[1;36m2\u001b[0m required \u001b[1;36m13.4\u001b[0m.\u001b[1;36m1\u001b[0m     \n",
      "\u001b[2;36m07:06:49-219446\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mrich\u001b[0m==\u001b[1;36m13.4\u001b[0m.\u001b[1;36m1\u001b[0m                       \n",
      "\u001b[2;36m07:06:56-999443\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: safetensors \u001b[1;36m0.3\u001b[0m.\u001b[1;36m3\u001b[0m required \u001b[1;36m0.3\u001b[0m.\u001b[1;36m1\u001b[0m\n",
      "\u001b[2;36m07:06:57-000725\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33msafetensors\u001b[0m==\u001b[1;36m0.3\u001b[0m.\u001b[1;36m1\u001b[0m                 \n",
      "\u001b[2;36m07:07:05-009994\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: timm \u001b[1;36m0.9\u001b[0m.\u001b[1;36m5\u001b[0m required \u001b[1;36m0.6\u001b[0m.\u001b[1;36m12\u001b[0m      \n",
      "\u001b[2;36m07:07:05-011262\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mtimm\u001b[0m==\u001b[1;36m0.6\u001b[0m.\u001b[1;36m12\u001b[0m                       \n",
      "\u001b[2;36m07:07:13-372411\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mtk\u001b[0m==\u001b[1;36m0.1\u001b[0m.\u001b[1;36m0\u001b[0m                          \n",
      "\u001b[2;36m07:07:20-777343\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: transformers \u001b[1;36m4.32\u001b[0m.\u001b[1;36m1\u001b[0m required    \n",
      "\u001b[2;36m                \u001b[0m         \u001b[1;36m4.30\u001b[0m.\u001b[1;36m2\u001b[0m                                                 \n",
      "\u001b[2;36m07:07:20-778754\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mtransformers\u001b[0m==\u001b[1;36m4.30\u001b[0m.\u001b[1;36m2\u001b[0m               \n",
      "\u001b[2;36m07:07:35-838715\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mvoluptuous\u001b[0m==\u001b[1;36m0.13\u001b[0m.\u001b[1;36m1\u001b[0m                 \n",
      "\u001b[2;36m07:07:43-350968\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Package wrong version: wandb \u001b[1;36m0.15\u001b[0m.\u001b[1;36m9\u001b[0m required \u001b[1;36m0.15\u001b[0m.\u001b[1;36m0\u001b[0m    \n",
      "\u001b[2;36m07:07:43-352226\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: \u001b[33mwandb\u001b[0m==\u001b[1;36m0.15\u001b[0m.\u001b[1;36m0\u001b[0m                      \n",
      "\u001b[2;36m07:07:53-849508\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing package: -e .                               \n",
      "\u001b[2;36m07:08:09-677390\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Configuring accelerate\u001b[33m...\u001b[0m                              \n",
      "\u001b[2;36m07:08:09-678821\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Could not automatically configure accelerate. Please   \n",
      "\u001b[2;36m                \u001b[0m         manually configure accelerate with the option in the   \n",
      "\u001b[2;36m                \u001b[0m         menu or with: accelerate config.                       \n",
      "Setup finished! Run \u001b[0;92m./gui.sh\u001b[0m to start.\n",
      "Please note if you'd like to expose your public server you need to run ./gui.sh --share\n",
      "Kohya_SS is done setting up!\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/bmaltais/kohya_ss.git /kaggle/working/kohya_ss\n",
    "%cd /kaggle/working/kohya_ss/\n",
    "# We checkout this branch, because the current version (2023-09-04) requires too much memory\n",
    "!git checkout 2853f4cec850557e83882a4072cfe416cb9c57d7\n",
    "!/kaggle/working/kohya_ss/setup.sh -n\n",
    "print(\"Kohya_SS is done setting up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up training environment\n",
    "1. Create a dataset called \"training-images\", put your images in there and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T07:31:02.939511Z",
     "iopub.status.busy": "2025-03-31T07:31:02.939087Z",
     "iopub.status.idle": "2025-03-31T07:31:04.533620Z",
     "shell.execute_reply": "2025-03-31T07:31:04.532650Z",
     "shell.execute_reply.started": "2025-03-31T07:31:02.939472Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/training-data/img/25_wny_style'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what you will use to trigger your lora\n",
    "prompt_trigger = \"wny_style\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create the directories\n",
    "os.makedirs(\"/kaggle/working/training-data/img\", exist_ok=True)\n",
    "os.makedirs(\"/kaggle/working/training-data/reg\", exist_ok=True)\n",
    "os.makedirs(\"/kaggle/working/my-dreambooth-lora\", exist_ok=True)\n",
    "os.makedirs(\"/kaggle/working/training-data/log\", exist_ok=True)\n",
    "\n",
    "!rm -r /kaggle/working/training-data/*\n",
    "# Copy the files\n",
    "shutil.copytree(\"/kaggle/input/d/kartiksindura/training-images\", f\"/kaggle/working/training-data/img/25_{prompt_trigger}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to train the model!\n",
    "Just play the below code cell, it will require several hours to run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T07:42:18.859080Z",
     "iopub.status.busy": "2025-03-31T07:42:18.858374Z",
     "iopub.status.idle": "2025-03-31T09:56:51.706355Z",
     "shell.execute_reply": "2025-03-31T09:56:51.705200Z",
     "shell.execute_reply.started": "2025-03-31T07:42:18.859049Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/kohya_ss\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "prepare tokenizers\n",
      "prepare tokenizers\n",
      "Using DreamBooth method.\n",
      "Using DreamBooth method.\n",
      "prepare images.\n",
      "found directory /kaggle/working/training-data/img/25_wny_style contains 127 image files\n",
      "No caption file found for 127 images. Training will continue without captions for these images. If class token exists, it will be used. / 127枚の画像にキャプションファイルが見つかりませんでした。これらの画像についてはキャプションなしで学習を続行します。class tokenが存在する場合はそれを使います。\n",
      "/kaggle/working/training-data/img/25_wny_style/A_Pink_Sunset.jpg\n",
      "/kaggle/working/training-data/img/25_wny_style/A_Spring_Afternoon.jpg\n",
      "/kaggle/working/training-data/img/25_wny_style/A_Spring_Night.jpg\n",
      "/kaggle/working/training-data/img/25_wny_style/A_Summer_Evening.jpg\n",
      "/kaggle/working/training-data/img/25_wny_style/After_Rain.jpg\n",
      "/kaggle/working/training-data/img/25_wny_style/Arise.jpg... and 122 more\n",
      "3175 train images with repeating.\n",
      "0 reg images.\n",
      "no regularization images / 正則化画像が見つかりませんでした\n",
      "[Dataset 0]\n",
      "  batch_size: 1\n",
      "  resolution: (1024, 1024)\n",
      "  enable_bucket: False\n",
      "\n",
      "  [Subset 0 of Dataset 0]\n",
      "    image_dir: \"/kaggle/working/training-data/img/25_wny_style\"\n",
      "    image_count: 127\n",
      "    num_repeats: 25\n",
      "    shuffle_caption: False\n",
      "    keep_tokens: 0\n",
      "    caption_dropout_rate: 0.0\n",
      "    caption_dropout_every_n_epoches: 0\n",
      "    caption_tag_dropout_rate: 0.0\n",
      "    color_aug: False\n",
      "    flip_aug: False\n",
      "    face_crop_aug_range: None\n",
      "    random_crop: False\n",
      "    token_warmup_min: 1,\n",
      "    token_warmup_step: 0,\n",
      "    is_reg: False\n",
      "    class_tokens: wny_style\n",
      "    caption_extension: .caption\n",
      "\n",
      "\n",
      "[Dataset 0]\n",
      "loading image sizes.\n",
      "  0%|                                                   | 0/127 [00:00<?, ?it/s]prepare images.\n",
      "100%|███████████████████████████████████████| 127/127 [00:00<00:00, 5428.50it/s]\n",
      "prepare dataset\n",
      "found directory /kaggle/working/training-data/img/25_wny_style contains 127 image files\n",
      "No caption file found for 127 images. Training will continue without captions for these images. If class token exists, it will be used. / 127枚の画像にキャプションファイルが見つかりませんでした。これらの画像についてはキャプションなしで学習を続行します。class tokenが存在する場合はそれを使います。\n",
      "/kaggle/working/training-data/img/25_wny_style/A_Pink_Sunset.jpg\n",
      "/kaggle/working/training-data/img/25_wny_style/A_Spring_Afternoon.jpg\n",
      "/kaggle/working/training-data/img/25_wny_style/A_Spring_Night.jpg\n",
      "/kaggle/working/training-data/img/25_wny_style/A_Summer_Evening.jpg\n",
      "/kaggle/working/training-data/img/25_wny_style/After_Rain.jpg\n",
      "/kaggle/working/training-data/img/25_wny_style/Arise.jpg... and 122 more\n",
      "3175 train images with repeating.\n",
      "0 reg images.\n",
      "no regularization images / 正則化画像が見つかりませんでした\n",
      "[Dataset 0]\n",
      "  batch_size: 1\n",
      "  resolution: (1024, 1024)\n",
      "  enable_bucket: False\n",
      "\n",
      "  [Subset 0 of Dataset 0]\n",
      "    image_dir: \"/kaggle/working/training-data/img/25_wny_style\"\n",
      "    image_count: 127\n",
      "    num_repeats: 25\n",
      "    shuffle_caption: False\n",
      "    keep_tokens: 0\n",
      "    caption_dropout_rate: 0.0\n",
      "    caption_dropout_every_n_epoches: 0\n",
      "    caption_tag_dropout_rate: 0.0\n",
      "    color_aug: False\n",
      "    flip_aug: False\n",
      "    face_crop_aug_range: None\n",
      "    random_crop: False\n",
      "    token_warmup_min: 1,\n",
      "    token_warmup_step: 0,\n",
      "    is_reg: False\n",
      "    class_tokens: wny_style\n",
      "    caption_extension: .caption\n",
      "\n",
      "\n",
      "[Dataset 0]\n",
      "loading image sizes.\n",
      "  0%|                                                   | 0/127 [00:00<?, ?it/s]preparing accelerator\n",
      "100%|███████████████████████████████████████| 127/127 [00:00<00:00, 5621.62it/s]\n",
      "prepare dataset\n",
      "preparing accelerator\n",
      "loading model for process 0/2\n",
      "load Diffusers pretrained models: stabilityai/stable-diffusion-xl-base-1.0, variant=fp16\n",
      "The config attributes {'add_watermarker': None} were passed to StableDiffusionXLPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
      "Keyword arguments {'add_watermarker': None} are not expected by StableDiffusionXLPipeline and will be ignored.\n",
      "The config attributes {'force_upcast': True} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "U-Net converted to original U-Net\n",
      "loading model for process 1/2\n",
      "load Diffusers pretrained models: stabilityai/stable-diffusion-xl-base-1.0, variant=fp16\n",
      "The config attributes {'add_watermarker': None} were passed to StableDiffusionXLPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
      "Keyword arguments {'add_watermarker': None} are not expected by StableDiffusionXLPipeline and will be ignored.\n",
      "The config attributes {'force_upcast': True} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "U-Net converted to original U-Net\n",
      "Enable memory efficient attention for U-Net\n",
      "Enable memory efficient attention for U-Net\n",
      "import network module: networks.lora\n",
      "[Dataset 0]\n",
      "caching latents.\n",
      "checking cache validity...\n",
      "100%|█████████████████████████████████████| 127/127 [00:00<00:00, 480755.06it/s]\n",
      "[Dataset 0]\n",
      "caching latents.\n",
      "checking cache validity...\n",
      "100%|████████████████████████████████████████| 127/127 [00:00<00:00, 519.33it/s]\n",
      "caching latents...\n",
      "0it [00:00, ?it/s]\n",
      "create LoRA network. base dim (rank): 32, alpha: 16.0\n",
      "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
      "create LoRA for Text Encoder 1:\n",
      "create LoRA network. base dim (rank): 32, alpha: 16.0\n",
      "neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
      "create LoRA for Text Encoder 1:\n",
      "create LoRA for Text Encoder 2:\n",
      "create LoRA for Text Encoder 2:\n",
      "create LoRA for Text Encoder: 264 modules.\n",
      "create LoRA for Text Encoder: 264 modules.\n",
      "create LoRA for U-Net: 722 modules.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "create LoRA for U-Net: 722 modules.\n",
      "enable LoRA for text encoder\n",
      "enable LoRA for U-Net\n",
      "prepare optimizer, data loader etc.\n",
      "use Adafactor optimizer | {'scale_parameter': False, 'relative_step': False, 'warmup_init': False}\n",
      "because max_grad_norm is set, clip_grad_norm is enabled. consider set to 0 / max_grad_normが設定されているためclip_grad_normが有効になります。0に設定して無効にしたほうがいいかもしれません\n",
      "constant_with_warmup will be good / スケジューラはconstant_with_warmupが良いかもしれません\n",
      "override steps. steps for 1 epochs is / 指定エポックまでのステップ数: 1588\n",
      "use Adafactor optimizer | {'scale_parameter': False, 'relative_step': False, 'warmup_init': False}\n",
      "because max_grad_norm is set, clip_grad_norm is enabled. consider set to 0 / max_grad_normが設定されているためclip_grad_normが有効になります。0に設定して無効にしたほうがいいかもしれません\n",
      "constant_with_warmup will be good / スケジューラはconstant_with_warmupが良いかもしれません\n",
      "running training / 学習開始\n",
      "  num train images * repeats / 学習画像の数×繰り返し回数: 3175\n",
      "  num reg images / 正則化画像の数: 0\n",
      "  num batches per epoch / 1epochのバッチ数: 1588\n",
      "  num epochs / epoch数: 1\n",
      "  batch size per device / バッチサイズ: 1\n",
      "  gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
      "  total optimization steps / 学習ステップ数: 1588\n",
      "steps:   0%|                                           | 0/1588 [00:00<?, ?it/s]\n",
      "epoch 1/1\n",
      "steps: 100%|█████████████████| 1588/1588 [2:06:49<00:00,  4.79s/it, loss=0.0895]\n",
      "saving checkpoint: /kaggle/working/my-dreambooth-lora/sdxl-dreambooth-lora.safetensors\n",
      "model saved.\n",
      "steps: 100%|█████████████████| 1588/1588 [2:13:42<00:00,  5.05s/it, loss=0.0895]\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/kohya_ss/\n",
    "!accelerate launch --num_cpu_threads_per_process=2 \"./sdxl_train_network.py\" \\\n",
    "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
    "  --train_data_dir=\"/kaggle/working/training-data/img\" \\\n",
    "  --output_dir=\"/kaggle/working/my-dreambooth-lora\" \\\n",
    "  --logging_dir=\"/kaggle/working/training-data/log\" \\\n",
    "  --resolution=\"1024,1024\" \\\n",
    "  --network_alpha=\"16\" \\\n",
    "  --network_dim=32 \\\n",
    "  --save_model_as=safetensors \\\n",
    "  --network_module=networks.lora \\\n",
    "  --text_encoder_lr=0.0004 \\\n",
    "  --unet_lr=0.0004 \\\n",
    "  --output_name=\"sdxl-dreambooth-lora\" \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --no_half_vae \\\n",
    "  --learning_rate=\"0.0004\" \\\n",
    "  --train_batch_size=\"1\" \\\n",
    "  --max_train_epochs=1 \\\n",
    "  --save_every_n_epochs=\"1\" \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --save_precision=\"fp16\" \\\n",
    "  --optimizer_type=\"Adafactor\" \\\n",
    "  --optimizer_args scale_parameter=False relative_step=False warmup_init=False \\\n",
    "  --max_data_loader_n_workers=\"0\" \\\n",
    "  --gradient_checkpointing \\\n",
    "  --xformers \\\n",
    "  --bucket_no_upscale \\\n",
    "  --noise_offset=0.1 \\\n",
    "  --cache_latents \\\n",
    "  --cache_latents_to_disk \\\n",
    "  --lowram \\\n",
    "  --mem_eff_attn \\\n",
    "  --min_snr_gamma=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We now have the model weights (safetensors) in the `my-dreambooth-lora` folder to the right."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7009422,
     "sourceId": 11223378,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30554,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
